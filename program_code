from scipy.spatial import distance as dist
from imutils.video import VideoStream
from imutils import face utils
from threading import Thread


import numpy as np
import argparse
import imutils
import time
import dlib
import cv2
import os
import pyttsx3
import serial


serialcomm = serial.Serial(’COM5’, 9600)
serialcomm.timeout = 1
engine = pyttsx3.init()

isDrowsy = False
start = cv2.getTickCount()
end = cv2.getTickCount()


def eye aspect ratio(eye):

    A = dist.euclidean(eye[1], eye[5])
    B = dist.euclidean(eye[2], eye[4])
    C = dist.euclidean(eye[0], eye[3])
    ear = (A + B) / (2.0 * C)
    return ear
    
    
def final ear(shape):

    (lStart, lEnd) = face utils.FACIAL LANDMARKS IDXS[”left eye”]
    (rStart, rEnd) = face utils.FACIAL LANDMARKS IDXS[”right eye”]
    leftEye = shape[lStart:lEnd]
    rightEye = shape[rStart:rEnd]
    leftEAR = eye aspect ratio(leftEye)
    rightEAR = eye aspect ratio(rightEye)
    ear = (leftEAR + rightEAR) / 2.0
    return (ear, leftEye, rightEye)
    
    
ap = argparse.ArgumentParser()
ap.add argument(”-w”, ”–webcam”, type=int, default=0, help=”index of webcam on system”)
args = vars(ap.parse args())


EYE_AR_THRESH = 0.3
EYE_AR_CONSEC_FRAMES = 30
COUNTER = 0


print(”− >Loading the predictor and detector...”)
detector = dlib.get frontal face detector()
detector = cv2.CascadeClassifier(”haarcascade frontalface default.xml”)

predictor = dlib.shape predictor(’shape predictor 68 face landmarks.dat’)
print(”− > Starting Video Stream”)
vs = VideoStream(src=args[”webcam”]).start()
time.sleep(1.0)


while True:

    frame = vs.read()
    frame = imutils.resize(frame, width=450)
    gray = cv2.cvtColor(frame, cv2.COLOR BGR2GRAY)
    rects = detector(gray, 0)
    rects = detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE SCALE IMAGE)


for rect in rects:

    for (x, y, w, h) in rects:
    
        rect = dlib.rectangle(int(x), int(y), int(x + w),int(y + h))
        shape = predictor(gray, rect)
        shape = face utils.shape to np(shape)
        eye = final ear(shape)
        ear = eye[0]
        leftEye = eye [1]
        rightEye = eye[2]
        leftEyeHull = cv2.convexHull(leftEye)
        rightEyeHull = cv2.convexHull(rightEye)
        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)
        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)
        print(isDrowsy)
        
        if ((ear < EYE_AR_THRESH) ):
        
            if (isDrowsy == False):
            
                COUNTER += 1
                start = cv2.getTickCount()
                print(”entered start”)
                isDrowsy = True
                
            else:
            
                isDrowsy = False
                
            if isDrowsy:
            
                print(”.”)
                end = cv2.getTickCount()
                print(start)
                print(end)
                time = (end - start)/ cv2.getTickFrequency()

            if time > 5:
                print(”drowsiness detected”)
                cv2.putText(frame, ”DROWSINESS ALERT!”, (10,30), cv2.FONT HERSHEY SIMPLEX, 0.7, (0, 0, 255), 2)
                engine.say(’Drowsiness Alert’)
                i = (”on”)
                serialcomm.write(i.encode())
                engine.runAndWait()
                break

            else:
                print(”—-”)
                cv2.putText(frame, ”EAR: :.2f”.format(ear), (300, 30), cv2.FONT HERSHEY SIMPLEX, 0.7, (0, 0, 255), 2)
                cv2.imshow(”Frame”, frame)
                key = cv2.waitKey(1) & 0xFF

            if key == ord(”q”):
                break
                
                
cv2.destroyAllWindows()
serialcomm.close()
vs.stop()
